{"cells":[{"cell_type":"markdown","source":["## Week 8\n\n**1. Stream Directory Data**\n\nIn the first part of the exercise, you will create a simple Spark streaming program that reads an input stream from a file source. The file source stream reader reads data from a directory on a file system. When a new file is added to the folder, Spark adds that fileâ€™s data to the input data stream.\n\nYou can find the input data for this exercise in the baby-names/streaming directory. This directory contains the baby names CSV file randomized and split into 98 individual files. You will use these files to simulate incoming streaming data.\n\n*a. Count the Number of Females*\n\nIn the first part of the exercise, you will create a Spark program that monitors an incoming directory. To simulate streaming data, you will copy CSV files from the baby-names/streaming directory into the incoming directory. Since you will be loading CSV data, you will need to define a schema before you initialize the streaming dataframe.\n\nFrom this input data stream, you will create a simple output data stream that counts the number of females and writes it to the console. Approximately every 10 seconds or so, copy a new file into the directory and report the console output. Do this for the first ten files.\n\n**2. Micro-Batching**\n\nRepeat the last step, but use a micro-batch interval to trigger the processing every 30 seconds. Approximately every 10 seconds or so, copy a new file into the directory and report the console output. Do this for the first ten files. How did the output differ from the previous example?"],"metadata":{}},{"cell_type":"markdown","source":["### Stream directory data"],"metadata":{}},{"cell_type":"code","source":["# load libraries\nfrom pyspark.sql import SparkSession\nfrom pyspark import SparkConf\nfrom pyspark import SparkContext\nfrom time import sleep\n\n# create spark context\nsc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# define static and streaming directory\nstatic_dir = '/FileStore/tables/babystatic/baby_names_csv-70f67.gz'\nstream_dir = '/FileStore/tables/babystream'\n\n# before streaming, use static data to define dataframe\nspark = SparkSession.builder.appName('strtst').getOrCreate()\nstatic = spark.read.csv(static_dir, header = True)\n\ndataschema = static.schema\n\nstatic.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- state: string (nullable = true)\n-- sex: string (nullable = true)\n-- year: string (nullable = true)\n-- name: string (nullable = true)\n-- count: string (nullable = true)\n\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["# check streaming\nstreaming = spark.readStream.schema(dataschema).csv(stream_dir)\n\ncounts = streaming.groupBy('sex').count()\ncounts"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">24</span><span class=\"ansired\">]: </span>DataFrame[sex: string, count: bigint]</div>"]}}],"execution_count":5},{"cell_type":"code","source":["# start streaming, print and stop\nstreamingquery = counts.writeStream.queryName('Counts').format('memory').outputMode('complete').start()\n\nfor i in range(5):\n  spark.sql('SELECT * FROM counts').show()\n  sleep(1)\n  \nstreamingquery.stop()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----+\nsex|count|\n+---+-----+\n+---+-----+\n\n+---+-----+\nsex|count|\n+---+-----+\n+---+-----+\n\n+---+-----+\nsex|count|\n+---+-----+\n+---+-----+\n\n+---+-----+\nsex|count|\n+---+-----+\n+---+-----+\n\n+---+-------+\nsex|  count|\n+---+-------+\n  F|2676642|\n  M|2123358|\nsex|     80|\n+---+-------+\n\n</div>"]}}],"execution_count":6}],"metadata":{"name":"2019-10-21 - DBFS Example","notebookId":839258186526848},"nbformat":4,"nbformat_minor":0}
